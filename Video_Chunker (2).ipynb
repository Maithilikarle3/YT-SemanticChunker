{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M0W53A5ekRG6"
      },
      "outputs": [],
      "source": [
        "!pip install yt-dlp gradio torchaudio spacy\n",
        "!python -m spacy download en_core_web_sm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/openai/whisper.git"
      ],
      "metadata": {
        "id": "xyhyVVNGkU6W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def download_audio(youtube_url):\n",
        "    from yt_dlp import YoutubeDL\n",
        "\n",
        "    output_path = \"audio.mp3\"\n",
        "\n",
        "    ydl_opts = {\n",
        "        \"format\": \"bestaudio/best\",\n",
        "        \"outtmpl\": \"audio.%(ext)s\",\n",
        "        \"postprocessors\": [{\n",
        "            \"key\": \"FFmpegExtractAudio\",\n",
        "            \"preferredcodec\": \"mp3\",\n",
        "            \"preferredquality\": \"192\",\n",
        "        }],\n",
        "    }\n",
        "\n",
        "    with YoutubeDL(ydl_opts) as ydl:\n",
        "        ydl.download([youtube_url])\n",
        "\n",
        "\n",
        "    if os.path.exists(\"audio.mp3.mp3\"):\n",
        "        os.rename(\"audio.mp3.mp3\", \"audio.mp3\")\n",
        "\n",
        "    return \"audio.mp3\""
      ],
      "metadata": {
        "id": "B6uVcM0ekYXu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transcribe_audio(audio_path, model):\n",
        "    result = model.transcribe(audio_path, word_timestamps=True)\n",
        "    return result"
      ],
      "metadata": {
        "id": "UDfsNecFkbEO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "model = whisper.load_model(\"medium\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2RT7TJX9kdsd",
        "outputId": "9b5760cb-aa40-4aa4-c86a-456e9202ff1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████████████████████████████████| 1.42G/1.42G [00:27<00:00, 56.1MiB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchaudio\n",
        "import torchaudio.functional as F\n",
        "\n",
        "def apply_vad(audio_path):\n",
        "    wav, sr = torchaudio.load(audio_path)\n",
        "    vad_audio = F.vad(wav, sample_rate=sr)\n",
        "    return vad_audio, sr"
      ],
      "metadata": {
        "id": "VcgtlMiukgBz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pydub.utils import mediainfo\n",
        "\n",
        "def get_audio_duration(file_path):\n",
        "    info = mediainfo(file_path)\n",
        "    return float(info['duration'])  #  seconds\n",
        "\n",
        "def get_dynamic_chunk_time(total_duration_sec):\n",
        "    if total_duration_sec < 300:    # less than 5 min\n",
        "        return 15\n",
        "    elif total_duration_sec < 900:  # 5–15 min\n",
        "        return 30\n",
        "    elif total_duration_sec < 1800: # 15–30 min\n",
        "        return 45\n",
        "    else:                           # over 30 min\n",
        "        return 60"
      ],
      "metadata": {
        "id": "S7BynT8Bkimx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "import json\n",
        "\n",
        "def semantic_chunking(transcription, voiced_segments,max_chunk_time):\n",
        "    nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "    segments = []\n",
        "    current_chunk = \"\"\n",
        "    start_time = None\n",
        "    current_duration = 0\n",
        "\n",
        "    for segment in transcription[\"segments\"]:\n",
        "        words = segment[\"words\"]\n",
        "        text = segment[\"text\"]\n",
        "        doc = nlp(text)\n",
        "\n",
        "        # Sentence segmentation\n",
        "        sentences = [sent.text.strip() for sent in doc.sents]\n",
        "\n",
        "        for sentence in sentences:\n",
        "            word_start_time = words[0][\"start\"]\n",
        "            word_end_time = words[-1][\"end\"]\n",
        "\n",
        "            if start_time is None:\n",
        "                start_time = word_start_time\n",
        "\n",
        "            new_duration = word_end_time - start_time\n",
        "\n",
        "\n",
        "            if new_duration <= max_chunk_time:\n",
        "                current_chunk += sentence + \" \"\n",
        "                current_duration = new_duration\n",
        "            else:\n",
        "\n",
        "                if current_chunk.strip():\n",
        "                    segments.append({\n",
        "                        \"chunk_id\": len(segments) + 1,\n",
        "                        \"chunk_length\": float(current_duration),\n",
        "                        \"total_time\": float(current_duration),\n",
        "                        \"text\": current_chunk.strip(),\n",
        "                        \"start_time\": float(start_time),\n",
        "                        \"end_time\": float(word_end_time)\n",
        "                    })\n",
        "\n",
        "\n",
        "                current_chunk = sentence + \" \"\n",
        "                start_time = word_start_time\n",
        "                current_duration = word_end_time - start_time\n",
        "\n",
        "    # Store the last chunk if it's not empty\n",
        "    if current_chunk.strip():\n",
        "        segments.append({\n",
        "            \"chunk_id\": len(segments) + 1,\n",
        "            \"chunk_length\": float(current_duration),\n",
        "            \"total_time\": float(current_duration),\n",
        "            \"text\": current_chunk.strip(),\n",
        "            \"start_time\": float(start_time),\n",
        "            \"end_time\": float(word_end_time)\n",
        "        })\n",
        "\n",
        "    return json.dumps(segments, indent=4)\n"
      ],
      "metadata": {
        "id": "xMZst1rAklSo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# Load LLM\n",
        "llm = pipeline(\"text2text-generation\", model=\"google/flan-t5-small\")\n",
        "#translator = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-en-hi\")\n",
        "translator = pipeline(\"translation\", model=\"facebook/m2m100_418M\", src_lang=\"en\", tgt_lang=\"hi\")\n",
        "# Define functions for each enhancement\n",
        "def generate_title(text):\n",
        "    prompt = f\"Generate a short title for this: {text}\"\n",
        "    return llm(prompt, max_length=30)[0]['generated_text']\n",
        "\n",
        "def summarize(text):\n",
        "    prompt = f\"Summarize in one sentence: {text}\"\n",
        "    return llm(prompt, max_length=50)[0]['generated_text']\n",
        "\n",
        "def tag_topic(text):\n",
        "    prompt = f\"Identify the topic of this text: {text}\"\n",
        "    return llm(prompt, max_length=10)[0]['generated_text']\n",
        "\n",
        "def enhanced_chunking(chunked_output):\n",
        "    enhanced_chunks = []\n",
        "    for chunk in chunked_output:\n",
        "        text = chunk['text']\n",
        "\n",
        "        # LLM enrichment (title, summary, etc.)\n",
        "        title = generate_title(text)\n",
        "        summary = summarize(text)\n",
        "        topic = tag_topic(text)\n",
        "        translated_text = translator(text, max_length=1024)[0]['translation_text']\n",
        "\n",
        "\n",
        "        chunk.update({\n",
        "            \"title\": title,\n",
        "            \"summary\": summary,\n",
        "            \"topic\": topic,\n",
        "            'translated_text_hi':translated_text\n",
        "        })\n",
        "\n",
        "        enhanced_chunks.append(chunk)\n",
        "\n",
        "    return enhanced_chunks\n"
      ],
      "metadata": {
        "id": "-enPK6QBkoRx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import json\n",
        "\n",
        "def process_youtube_video(youtube_url):\n",
        "    try:\n",
        "        #  1: Download and process audio\n",
        "        audio_path = download_audio(youtube_url)\n",
        "        voiced_audio, sr = apply_vad(audio_path)\n",
        "\n",
        "        #  2: Transcribe audio\n",
        "        transcription = transcribe_audio(audio_path, model)\n",
        "\n",
        "        #  3: Get dynamic chunk size\n",
        "        duration = get_audio_duration(audio_path)\n",
        "        max_chunk_time = get_dynamic_chunk_time(duration)\n",
        "\n",
        "        #  4: Semantic chunking\n",
        "        chunked_output = semantic_chunking(transcription, voiced_audio, max_chunk_time=max_chunk_time)\n",
        "        chunked_output = json.loads(chunked_output)  # Convert to JSON\n",
        "\n",
        "        #  5: LLM and translation enrichment\n",
        "        enhanced_chunks = enhanced_chunking(chunked_output)\n",
        "\n",
        "        # Handle empty output\n",
        "        if not enhanced_chunks:\n",
        "            return \"<p style='color:red; font-size:18px;'>⚠️ No transcript chunks found. Try another video.</p>\"\n",
        "\n",
        "        #  Dark gray background for readability\n",
        "        formatted_chunks = \"<div style='font-family:sans-serif; background-color:#1f2937; padding:15px; border-radius:10px;'>\"\n",
        "        for chunk in enhanced_chunks:\n",
        "            formatted_chunks += f\"\"\"\n",
        "            <div style='border: 2px solid #444; padding: 15px; margin-bottom: 15px; border-radius: 8px;\n",
        "                        background: #374151; box-shadow: 2px 2px 8px rgba(0,0,0,0.3); color: white;'>\n",
        "                <h3 style='color:white;'>🔹 {chunk['title']}</h3>\n",
        "                <p style='color:white; font-size:15px;'><b>⏳ Time:</b> {chunk['start_time']} - {chunk['end_time']} ({chunk['chunk_length']}s)</p>\n",
        "                <p style='color:white; font-size:15px;'><b>📝 Text:</b> {chunk['text']}</p>\n",
        "                <p style='color:white; font-size:15px;'><b>📌 Topic:</b> {chunk['topic']}</p>\n",
        "                <p style='color:white; font-size:15px;'><b>📖 Summary:</b> {chunk['summary']}</p>\n",
        "                <p style='color:white; font-size:15px;'><b>🌎 Hindi Translation:</b> {chunk['translated_text_hi']}</p>\n",
        "            </div><br>\n",
        "            \"\"\"\n",
        "        formatted_chunks += \"</div>\"\n",
        "\n",
        "        return formatted_chunks\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"<p style='color:red;'>⚠️ Error: {str(e)}</p>\"\n",
        "\n",
        "# Gradio UI\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"# 🎬 **YouTube Semantic Chunker**\", elem_id=\"header\")\n",
        "    gr.Markdown(\"Extract AI-enhanced transcript chunks with topics, summaries, and Hindi translations.\", elem_id=\"subheader\")\n",
        "\n",
        "    with gr.Row():\n",
        "        youtube_input = gr.Textbox(label=\"📺 **YouTube Video URL**\", placeholder=\"Paste YouTube link here...\")\n",
        "        run_btn = gr.Button(\"🔍 **Analyze Video**\", elem_id=\"analyze-btn\")\n",
        "\n",
        "    results = gr.HTML(\"\")\n",
        "\n",
        "    run_btn.click(fn=process_youtube_video, inputs=[youtube_input], outputs=[results])\n",
        "\n",
        "demo.launch()\n"
      ],
      "metadata": {
        "id": "n5yhzPBRksYS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}